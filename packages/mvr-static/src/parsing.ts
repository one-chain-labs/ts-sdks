// Copyright (c) Mysten Labs, Inc.
// SPDX-License-Identifier: Apache-2.0
import { existsSync, mkdirSync, writeFileSync } from 'fs';
import { readFile } from 'fs/promises';
import { dirname, extname, isAbsolute, join } from 'path';
import { parseArgs } from 'util';
import type { NamedPackagesPluginCache } from '@onelabs/sui/src/transactions';
import { isValidNamedPackage } from '@onelabs/sui/utils';
import { prompt } from 'enquirer';
import { glob } from 'glob';
import { format } from 'prettier';

const TYPES_AND_TARGET_MATCHES = /[@a-zA-Z0-9/.-]+::[a-zA-Z0-9_]+::[a-zA-Z0-9_]+/g;
const MVR_NAME_MATCHES = /[@a-zA-Z0-9/.-]+::/g;

const DEFAULT_INCLUDE_PATTERNS = ['**/*.{js,ts,jsx,tsx,mjs,cjs}'];
const DEFAULT_EXCLUDE_PATTERNS = ['node_modules/**', '**/.*'];
const DEFAULT_FILE_NAME = `mvr.ts`;

const MAX_BATCH_SIZE = 25; // files to process per batch.
const MAINNET_API_URL = 'https://mainnet.mvr.mystenlabs.com';
const TESTNET_API_URL = 'https://testnet.mvr.mystenlabs.com';

const WARNING_MESSAGE = `/**
 * This file is automatically generated by the mvr SDK.
 * You can edit this file, but it will be overwritten on the next run.
 * You should check this file in your version control system.
 *
 * Run this script before building your project to ensure that the mvr.ts file stays up to date.
 *
 * You can use this pre-built cache when initializing your "NamedPackagesPlugin" by calling
 * \`getMvrCache("mainnet")\` or \`getMvrCache("testnet")\`
 */
`;

const { values: args } = parseArgs({
	options: {
		directory: {
			type: 'string',
			default: '.',
			short: 'd',
		},
		output: {
			type: 'string',
			default: DEFAULT_FILE_NAME,
			short: 'o',
		},
		depth: {
			type: 'string',
			default: '10',
			short: 'd',
		},
		'url-mainnet': {
			type: 'string',
			default: MAINNET_API_URL,
		},
		'url-testnet': {
			type: 'string',
			default: TESTNET_API_URL,
		},
		include: {
			type: 'string',
			multiple: true,
			default: DEFAULT_INCLUDE_PATTERNS,
			short: 'i',
		},
		exclude: {
			type: 'string',
			multiple: true,
			default: DEFAULT_EXCLUDE_PATTERNS,
			short: 'e',
		},
		force: {
			type: 'boolean',
			default: false,
			short: 'f',
		},
	},
});

export async function parser() {
	const path = isAbsolute(args.output) ? args.output : join(process.cwd(), args.output);
	const dir = dirname(path);

	if (!existsSync(dir)) mkdirSync(dir, { recursive: true });

	if (!isSupportedFile(path))
		throw new Error(
			`Unsupported file type: ${path}. Please use a .ts (or equivalent) file name for the output.`,
		);

	if (existsSync(path) && !args.force) {
		const { overwrite } = (await prompt({
			type: 'confirm',
			name: 'overwrite',
			message: `The file ${path} already exists. Do you want to overwrite it?`,
		})) as { overwrite: boolean };

		console.log(`Skipping generation of MVR file.`);
		if (!overwrite) return process.exit(1);
	}

	console.log(`Generating ${args.output}...`);

	const detectedNames = await findNames({});

	const { mainnet, testnet } = await crossNetworkResolution(detectedNames);

	await writeOutputFile(path, mainnet, testnet);
}

async function writeOutputFile(
	outDir: string,
	mainnet: NamedPackagesPluginCache,
	testnet: NamedPackagesPluginCache,
) {
	const outputFile = `${WARNING_MESSAGE}
const mainnetResolution = ${JSON.stringify(mainnet, null, 2)}
const testnetResolution = ${JSON.stringify(testnet, null, 2)}

export function getMvrCache(network: 'mainnet' | 'testnet') {
	return network === 'mainnet' ? mainnetResolution : testnetResolution;
}\n
`;

	writeFileSync(outDir, await format(outputFile, { parser: 'typescript' }), 'utf8');
}

export async function crossNetworkResolution(detectedNames: Set<string>) {
	const packages = Array.from(detectedNames).filter((x) => !x.includes('::'));
	const types = Array.from(detectedNames).filter((x) => x.includes('::'));

	const [mainnetPackages, mainnetTypes, testnetPackages, testnetTypes] = await Promise.all([
		resolvePackages(packages, args['url-mainnet']),
		resolveTypes(types, args['url-mainnet']),
		resolvePackages(packages, args['url-testnet']),
		resolveTypes(types, args['url-testnet']),
	]);

	return {
		mainnet: {
			packages: mainnetPackages,
			types: mainnetTypes,
		},
		testnet: {
			packages: testnetPackages,
			types: testnetTypes,
		},
	};
}

async function resolvePackages(packages: string[], apiUrl: string) {
	const batches = batch(packages, 50);

	const results: Record<string, string> = {};

	await Promise.all(
		batches.map(async (batch) => {
			const response = await fetch(`${apiUrl}/v1/resolution/bulk`, {
				method: 'POST',
				headers: { 'Content-Type': 'application/json' },
				body: JSON.stringify({
					names: batch,
				}),
			});

			if (!response.ok) {
				const errorBody = await response.json().catch(() => ({}));
				throw new Error(`Failed to resolve packages: ${errorBody?.message}`);
			}

			const data = await response.json();

			if (!data?.resolution) return;

			for (const pkg of Object.keys(data?.resolution)) {
				const pkgData = data.resolution[pkg]?.package_id;

				if (!pkgData) continue;

				results[pkg] = pkgData;
			}
		}),
	);

	return results;
}

// TODO: Switch to `/struct-definition/bulk` endpoint when released,
// as this endpoint will be the right one for "non-nested" struct resolution.
// The current endpoint will fail with "generic" parameter lookups (which are not existent)
// on this parser.
async function resolveTypes(types: string[], apiUrl: string) {
	const batches = batch(types, 50);

	const results: Record<string, string> = {};

	await Promise.all(
		batches.map(async (batch) => {
			const response = await fetch(`${apiUrl}/v1/struct-definition/bulk`, {
				method: 'POST',
				headers: { 'Content-Type': 'application/json' },
				body: JSON.stringify({
					types: batch,
				}),
			});

			if (!response.ok) {
				const errorBody = await response.json().catch(() => ({}));
				throw new Error(`Failed to resolve types: ${errorBody?.message}`);
			}

			const data = await response.json();

			if (!data?.resolution) return;

			for (const type of Object.keys(data?.resolution)) {
				const typeData = data.resolution[type]?.type_tag;
				if (!typeData) continue;

				results[type] = typeData;
			}
		}),
	);

	return results;
}

/**
 * Finds all the MVR names in the given directory.
 * @param directory - The directory to search for MVR names.
 * @returns A set of all the MVR names found in the directory.
 */
export async function findNames({
	directory = args.directory,
	include = args.include,
	exclude = args.exclude,
	depth = parseInt(args.depth),
	output = args.output,
}: {
	directory?: string;
	include?: string[];
	exclude?: string[];
	depth?: number;
	output?: string;
}) {
	const detectedNames = new Set<string>();
	const excluded = [...exclude, output];

	const files = glob.sync(include, {
		ignore: excluded,
		cwd: directory,
		maxDepth: depth,
		absolute: true,
	});

	// We batch the files to avoid trying to open too many files at once.
	const batches = batch(files);

	for (const batch of batches) {
		await processFilesBatch(batch, detectedNames);
	}

	return detectedNames;
}

/**
 * Finds all the MVR names in the given files.
 */
async function processFilesBatch(files: string[], detectedNames: Set<string>) {
	await Promise.all(
		files.map(async (file) => {
			const content = await readFile(file, 'utf8');
			extractMvrNames(content).forEach((name) => detectedNames.add(name));
		}),
	);
}

/**
 * Extracts all the MVR names from the given file's data (content).
 */
function extractMvrNames(content: string) {
	const relevantNames = new Set<string>();
	// find all "fully qualified" matches.
	const fullQualifiedMatches = [...content.matchAll(TYPES_AND_TARGET_MATCHES)];
	fullQualifiedMatches.forEach((match) => {
		const [pkg] = match[0].split('::');

		if (!isValidNamedPackage(pkg)) return;

		relevantNames.add(match[0]);
	});

	// find all "plain" name matches
	const plainNameMatches = [...content.matchAll(MVR_NAME_MATCHES)];
	plainNameMatches.forEach((match) => {
		const [pkg] = match[0].split('::');
		if (!isValidNamedPackage(pkg)) return;

		relevantNames.add(pkg);
	});

	return relevantNames;
}

/**
 * Batch the given array into smaller arrays of the given size.
 */
function batch<T>(array: T[], batchSize: number = MAX_BATCH_SIZE) {
	const result = [];
	for (let i = 0; i < array.length; i += batchSize) {
		result.push(array.slice(i, i + batchSize)); // Create batches
	}
	return result;
}

function isSupportedFile(filePath: string) {
	const ext = extname(filePath).toLowerCase();
	return ['.js', '.mjs', '.cjs', '.ts', '.mts', '.cts'].includes(ext);
}
